#SlurmctldHost=control(control.yourdomain.com)
#
#MailProg=/bin/mail
MpiDefault=none
#MpiParams=ports=#-#
ProctrackType=proctrack/cgroup
ReturnToService=1
SlurmctldPidFile=/run/slurm/slurmctld.pid
#SlurmctldPort=6817
SlurmdPidFile=/run/slurm/slurmd.pid
#SlurmdPort=6818
SlurmdSpoolDir=/var/spool/slurmd
SlurmUser=slurm
#SlurmdUser=root
StateSaveLocation=/var/spool/slurmctld
SwitchType=switch/none
TaskPlugin=task/cgroup,task/affinity
#
#
# TIMERS
#KillWait=30
#MinJobAge=300
#SlurmctldTimeout=120
#SlurmdTimeout=300
#
#
# SCHEDULING
FastSchedule=1
SchedulerType=sched/backfill
SelectType=select/cons_res
#cons_tres if you want to use gpus
SelectTypeParameters=CR_Core
#
#
# LOGGING AND ACCOUNTING
ClusterName=cluster
#SlurmctldDebug=info
SlurmctldLogFile=/var/log/slurm-llnl/slurmctld.log
#SlurmdDebug=info
SlurmdLogFile=/var/log/slurm-llnl/slurmd.log
AccountingStorageLoc=/var/log/slurm-llnl/accounting.log
AccountingStorageType=accounting_storage/filetxt
AccountingStoreJobComment=YES
JobCompType=jobcomp/filetxt
JobCompLoc=/var/log/slurm-llnl/jobs.log
JobAcctGatherFrequency=30
JobAcctGatherType=jobacct_gather/linux

# COMPUTE NODES
NodeName=tesla NodeAddr=tesla.yourdomain.com CPUs=80 RealMemory=515657 Sockets=2 CoresPerSocket=20 ThreadsPerCore=2 State=UNKNOWN
#add this to the node if you want to use gpus, has to be edited to fit your node!  Gres=gpu:tesla:2,mps:400
# PARTITIONS
PartitionName=debug Nodes=tesla Default=YES MaxTime=INFINITE State=UP
